
import streamlit as st 
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_openai import ChatOpenAI
from langchain import hub 
from langchain.chains import RetrievalQA
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate


load_dotenv()

st.set_page_config(
    page_title="ì†Œë“ì„¸ ì±—ë´‡", 
    page_icon="ğŸ¤–"
) 

st.title("ğŸ¤– ì†Œë“ì„¸ ì±—ë´‡")
st.caption("ì†Œë“ì„¸ ê´€ë ¨ ì§ˆë¬¸ì„ ë¬¼ì–´ë³´ì„¸ìš”.")

if "message_list" not in st.session_state:
    st.session_state.message_list = []

for message in st.session_state.message_list:
    with st.chat_message(message["role"]):
        st.write(message["content"])

def get_ai_message(user_message):


    embedding = OpenAIEmbeddings(model = "text-embedding-3-large")
    index_name = "table-markdown-index"
    database = PineconeVectorStore.from_existing_index(
        embedding=embedding,
        index_name=index_name
    )


    llm = ChatOpenAI(model="gpt-4o")
    prompt = hub.pull("rlm/rag-prompt")
    retriever = database.as_retriever(search_kwargs={'k': 4})


    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type_kwargs={"prompt": prompt},
        retriever=retriever
    )

    dictionary = ["ì‚¬ëŒì„ ë‚˜íƒ€ë‚´ëŠ” í‘œí˜„ -> ê±°ì£¼ì"]

    prompt = ChatPromptTemplate.from_template(f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³´ê³ , ìš°ë¦¬ì˜ ì‚¬ì „ì„ ì°¸ê³ í•´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•´ì£¼ì„¸ìš”.
    ë§Œì•½ ë³€ê²½í•  í•„ìš”ê°€ ì—†ë‹¤ê³  íŒë‹¨ëœë‹¤ë©´, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë³€ê²½í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.
    ë³€ê²½ì´ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì§ˆë¬¸ë§Œ ë¦¬í„´í•´ì£¼ì„¸ìš” ë³€ê²½ì´ í•„ìš” ì—†ë‹¤ë©´ ì§ˆë¬¸ì€ ë¦¬í„´í•´ì£¼ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤.
    ì‚¬ì „: {dictionary}

    ì§ˆë¬¸: {{question}}                                      

    """)

    dictionary_chain = prompt | llm | StrOutputParser()
    tax_chain = {"query" : dictionary_chain} | qa_chain

    ai_message = tax_chain.invoke({"question": user_message})
    return ai_message["result"]






if user_question := st.chat_input(placeholder = "ì†Œë“ì„¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”."):
    with st.chat_message("user"):
        st.write(user_question)
    st.session_state.message_list.append(
        {"role": "user", "content": user_question}
    )
    ai_message = get_ai_message(user_question)
    with st.chat_message("ai"):
        st.write(ai_message)
    st.session_state.message_list.append(
        {"role": "ai", "content": ai_message}
    )
